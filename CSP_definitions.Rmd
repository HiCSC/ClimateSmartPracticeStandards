---
title: "Climate Smart Practices"
author: "Todd-Brown, Katherine"
date: "2024-01-23"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(pdftools)
library(yaml)

knitr::opts_chunk$set(echo = TRUE)
```

```{r}
directYAML <- 'data_lvl01'

pdfFiles <- list.files(path = 'USDA_CSP_pdf', full.names = TRUE, recursive = TRUE)

#temp <- pdf_text(pdf = 'CSP/Data Extraction Helping Circle_Practice Standards and Deviations/311_Alley Cropping/311_PI_CPS_Alley_Cropping_2018.pdf')
```

## Line by line parser

```{r}
#high priority 
#Windbreak (380) #17 and #18
#Forest Farming (379) #15 #16

for(sourcePDF in pdfFiles){
  org_temp <- pdf_text(pdf = sourcePDF)
  
  #####Clean up text ########
  
  #remove boilerplate NRCS fair practice declariation
  temp <- str_remove(org_temp, 
                     regex('NRCS reviews and periodically updates conservation practice standards.*$', 
                           dotall = TRUE))
  
  #remove boilerplate NRCS fair practice declariation
  temp <- str_remove(temp, 
                     regex('NRCS reviews and periodically updates conservation practice standards.*$', 
                           dotall = TRUE))
  
  
  code <- str_extract(basename(sourcePDF), '^\\d{3}')
  practiceName <- str_extract(basename(sourcePDF), '(?<=\\d{3}_)\\w*(?=_\\w+_CPS)')
  standard <- str_extract(basename(sourcePDF), '(?<=_)[^_]*(?=_CPS)')
  year <- str_extract(basename(sourcePDF), '\\d{4}(?=.pdf)')
  
  #keep the type of practice and the date as the version
  version <- str_replace_all(str_remove_all(
    str_extract(temp[length(temp)], 'NRCS, .*\\n .* \\d{4}\n'),
    pattern = '\\n'),
    pattern = '\\s{2,}', replacement = ' - ') %>%
    str_remove(pattern = 'NRCS, ')
  
  #remove the version from the text to be processed so that the page text wraps
  temp <- str_remove(temp, 'NRCS, .*\\n .* \\d{4}\\n')
  
  #extract the header from the first page before the definition
  header <- unlist(str_split(trimws(str_extract(string = temp[1], pattern = '^[\\w\\W]*(?=DEFINITION)')), pattern='\\n?\\n?\\s{2,}'))
  
  unitAbv <- header[str_detect(header, '\\(\\w+\\)')]
  practiceName <- header[! header %in% c("Natural Resources Conservation Service",
                                         "CONSERVATION PRACTICE STANDARD",
                                         "United States Department of Agriculture") &
                           ! str_detect(header, '\\(\\w+\\)') &
                           ! str_detect(header, '\\d')]
  
  
  #remove the header from the text
  temp[1] <- str_remove(string = temp[1], pattern = '^[\\w\\W]*(?=DEFINITION)')
  
  #Remove the practice code and page from the top of the page so that the text wraps
  #temp <- str_remove(temp, str_replace_all(str_replace_all(header[2], '-', '\\.'), '\\d$', '\\\\d'))
  temp <- str_remove(temp, '^\\s*\\d{1,}\\-CPS\\-\\d+\\n')
  
  
  ###### Define dimentions ####
  
  dimentions.ls <- list(
    definition = regex('(?<=DEFINITION).*(?=PURPOSE)', dotall = TRUE),
    purpose = regex('(?<=PURPOSE).*(?=CONDITIONS WHERE PRACTICE APPLIES)', dotall = TRUE),
    conditions = regex('(?<=CONDITIONS WHERE PRACTICE APPLIES).*(?=CRITERIA)', dotall=TRUE),
    criteia = regex('(?<=CRITERIA).*(?=CONSIDERATIONS)', dotall=TRUE),
    considerations = regex('(?<=CONSIDERATIONS).*(?=PLANS AND SPECIFICATIONS)', dotall = TRUE),
    plans_specifications = regex('(?<=PLANS AND SPECIFICATIONS)[\\w\\W]*(?=OPERATION AND MAINTENANCE)', dotall=TRUE),
    operations_maintanance = regex('(?<=OPERATION AND MAINTENANCE)[\\w\\W]*(?=REFERENCES)', dotall=TRUE),
    references =  regex('(?<=REFERENCES).*', dotall = TRUE))
  
  ## Apply to the lines
  elements <- plyr::llply(dimentions.ls, .fun = function(xx){
    ans <- str_extract(pattern = xx, string = paste0(temp, collapse = '\n'))
    ans <- str_trim(ans)
    if(str_detect("(?<=CRITERIA).*(?=CONSIDERATIONS)", xx) &
       str_detect(ans, '((General)|(Additional)) Criteria')){
      ans <- unlist(str_split(ans, 
                              pattern = regex('\\n*\\s*((General)|(Additional)) Criteria ', dotall=TRUE)))
      ans <- ans[ans != '']
      ans_name <- str_extract(ans, '^.*(?=\\n)')
      ans <- str_remove_all(ans, '^.*\\n')
      ans <- as.list(str_replace(ans, '\\n', '\n\n'))
      ans <- setNames(ans, ans_name)
    }else if(str_detect("(?<=CONSIDERATIONS).*(?=PLANS AND SPECIFICATIONS)", xx) &
             str_detect(ans, '\\n*\\s*Considerations for')){
      ans <- unlist(str_split(ans, 
                              pattern = regex('\\n*\\s*Considerations for', dotall=TRUE)))
      ans <- str_trim(ans[ans != ''])
      ans_name <- str_extract(ans, '^.*(?=\\n)')
      ans <- str_remove_all(ans, '^.*\\n')
      ans <- as.list(str_replace(ans, '\\n', '\n\n'))
      ans <- setNames(ans, ans_name)
    }else{
      ans <- as.list(ans) 
    }
    ans <- plyr::llply(ans, .fun = function(zz){
      #pair any list with the line before it by removing the \n\n
      ans3 <- str_remove_all(zz, pattern = '\\n(?=\\n\\s+•)')
      ans3 <- as.list(unlist(str_split(ans3, pattern = '\\n\\n')))
      ans3 <- str_split(str_trim(ans3), pattern = '\\n(?=\\s+•)')
      ans3 <- plyr::llply(ans3, .fun = function(yy){
        ans2 <- str_replace_all(string = yy, 
                                pattern = '(?<=\\S)\\n?\\s+', 
                                replacement = ' ')
        ans2 <- str_remove_all(string = ans2, pattern = '\\s+$')
        return(ans2)
      })
      return(ans3)
    })
    if(length(ans) == 1){
      ans <- unlist(ans)
    }
    return(ans)
  })
  elements2 <- c(list(practice_name = practiceName,
                      practice_code = code,
                      unit = unitAbv,
                      version = version), elements)
  write_file(as.yaml(elements2), file = #file.path(directYAML, 'test.yaml')
               file.path(directYAML, paste0(str_remove(basename(sourcePDF), 'pdf'), 'yaml'))
  )
}
```

## To Dataframe

```{r eval=FALSE}
#high priority 
#Windbreak (380) #17 and #18
#Forest Farming (379) #15 #16

allPractices <- plyr::ldply(setNames(pdfFiles[15:18], pdfFiles[15:18]), .id = 'filename',
                            .fun = function(sourcePDF){
  org_temp <- pdf_text(pdf = sourcePDF)
  
  #####Clean up text ########
  
  #remove boilerplate NRCS fair practice declariation
  temp <- str_remove(org_temp, 
                     regex('NRCS reviews and periodically updates conservation practice standards.*$', 
                           dotall = TRUE))
  
  #remove boilerplate NRCS fair practice declariation
  temp <- str_remove(temp, 
                     regex('NRCS reviews and periodically updates conservation practice standards.*$', 
                           dotall = TRUE))
  
  
  code <- str_extract(basename(sourcePDF), '^\\d{3}')
  practiceName <- str_extract(basename(sourcePDF), '(?<=\\d{3}_)\\w*(?=_\\w+_CPS)')
  standard <- str_extract(basename(sourcePDF), '(?<=_)[^_]*(?=_CPS)')
  year <- str_extract(basename(sourcePDF), '\\d{4}(?=.pdf)')
  
  #keep the type of practice and the date as the version
  version <- str_replace_all(str_remove_all(
    str_extract(temp[length(temp)], 'NRCS, .*\\n .* \\d{4}\n'),
    pattern = '\\n'),
    pattern = '\\s{2,}', replacement = ' - ') %>%
    str_remove(pattern = 'NRCS, ')
  
  #remove the version from the text to be processed so that the page text wraps
  temp <- str_remove(temp, 'NRCS, .*\\n .* \\d{4}\\n')
  
  #extract the header from the first page before the definition
  header <- unlist(str_split(trimws(str_extract(string = temp[1], pattern = '^[\\w\\W]*(?=DEFINITION)')), pattern='\\n?\\n?\\s{2,}'))
  
  unitAbv <- header[str_detect(header, '\\(\\w+\\)')]
  practiceName <- header[! header %in% c("Natural Resources Conservation Service",
                                         "CONSERVATION PRACTICE STANDARD",
                                         "United States Department of Agriculture") &
                           ! str_detect(header, '\\(\\w+\\)') &
                           ! str_detect(header, '\\d')]
  
  
  #remove the header from the text
  temp[1] <- str_remove(string = temp[1], pattern = '^[\\w\\W]*(?=DEFINITION)')
  
  #Remove the practice code and page from the top of the page so that the text wraps
  #temp <- str_remove(temp, str_replace_all(str_replace_all(header[2], '-', '\\.'), '\\d$', '\\\\d'))
  temp <- str_remove(temp, '^\\s*\\d{1,}\\-CPS\\-\\d+\\n')
  
  
  ###### Define dimentions ####
  
  dimentions.ls <- list(
    definition = regex('(?<=DEFINITION).*(?=PURPOSE)', dotall = TRUE),
    purpose = regex('(?<=PURPOSE).*(?=CONDITIONS WHERE PRACTICE APPLIES)', dotall = TRUE),
    conditions = regex('(?<=CONDITIONS WHERE PRACTICE APPLIES).*(?=CRITERIA)', dotall=TRUE),
    criteia = regex('(?<=CRITERIA).*(?=CONSIDERATIONS)', dotall=TRUE),
    considerations = regex('(?<=CONSIDERATIONS).*(?=PLANS AND SPECIFICATIONS)', dotall = TRUE),
    plans_specifications = regex('(?<=PLANS AND SPECIFICATIONS)[\\w\\W]*(?=OPERATION AND MAINTENANCE)', dotall=TRUE),
    operations_maintanance = regex('(?<=OPERATION AND MAINTENANCE)[\\w\\W]*(?=REFERENCES)', dotall=TRUE),
    references =  regex('(?<=REFERENCES).*', dotall = TRUE))
  
  ## Apply to the lines
  elements <- plyr::ldply(dimentions.ls, .id = 'dimention', .fun = function(xx){
    ans <- str_extract(pattern = xx, string = paste0(temp, collapse = '\n'))
    ans <- str_trim(ans)
    if(str_detect("(?<=CRITERIA).*(?=CONSIDERATIONS)", xx) &
       str_detect(ans, '((General)|(Additional)) Criteria')){
      ans <- unlist(str_split(ans, 
                              pattern = regex('\\n*\\s*((General)|(Additional)) Criteria ', dotall=TRUE)))
      ans <- ans[ans != '']
      ans_name <- str_extract(ans, '^.*(?=\\n)')
      ans <- str_remove_all(ans, '^.*\\n')
      ans <- as.list(str_replace(ans, '\\n', '\n\n'))
      ans <- setNames(ans, ans_name)
    }else if(str_detect("(?<=CONSIDERATIONS).*(?=PLANS AND SPECIFICATIONS)", xx) &
             str_detect(ans, '\\n*\\s*Considerations for')){
      ans <- unlist(str_split(ans, 
                              pattern = regex('\\n*\\s*Considerations for', dotall=TRUE)))
      ans <- str_trim(ans[ans != ''])
      ans_name <- str_extract(ans, '^.*(?=\\n)')
      ans <- str_remove_all(ans, '^.*\\n')
      ans <- as.list(str_replace(ans, '\\n', '\n\n'))
      ans <- setNames(ans, ans_name)
    }else{
      ans <- as.list(ans) 
    }
    ans <- setNames(ans, 1:length(ans))
    
    ans <- plyr::ldply(ans, .id = 'term', .fun = function(zz){
      #pair any list with the line before it by removing the \n\n
      ans3 <- str_remove_all(zz, pattern = '\\n(?=\\n\\s+•)')
      ans3 <- as.list(unlist(str_split(ans3, pattern = '\\n\\n')))
      ans3 <- str_split(str_trim(ans3), pattern = '\\n(?=\\s+•)')
      
      ans3 <- setNames(ans3, 1:length(ans3))
      
      ans3 <- plyr::ldply(ans3, .id = 'clause', .fun = function(yy){
        ans2 <- str_replace_all(string = yy, 
                                pattern = '(?<=\\S)\\n?\\s+', 
                                replacement = ' ')
        ans2 <- str_remove_all(string = ans2, pattern = '\\s+$')
        return(tibble(line = 1:length(ans2), 
                      text = ans2))
      })
      return(ans3)
    })
    
    return(ans)
  })
  
  
  elements2 <- bind_rows(tibble(dimention = c('practice_name', 'practice_code', 'unit', 'version'),
                      text = c(practiceName, code, unitAbv, version)), elements)

  
})

comparison <- allPractices %>%
  mutate(practice = str_extract(filename, '(?<=/)\\d{3}(?=_)'),
         region = str_extract(filename, '[^_]+(?=_CPS)')) %>%
  select(practice, region, dimention, term, clause, line, text) 

PIA.df <- comparison %>%
  filter(region == 'PIA') %>%
  select(practice, dimention, text)

NHCP.df <- comparison %>%
  filter(region == 'NHCP') %>%
  select(practice, dimention, text)

onlyPIA.cd <- anti_join(PIA.df, NHCP.df)
```


#Standard differences

## CSP 315 Herbaceous Weed Treatement

NHCP standards allow Prescribed Burning (Code 338) and Forage Harvest Management (Code 511), where as PI standards do not.

```{sh}
diff data_lvl01/315_Herbaceous_Weed_Treatment_NHCP_CPS_10_2020.yaml data_lvl01/315_Herbaceous_Weed_Treatment_PI_CPS_2022.yaml
```

## CSP 317 Composting Facility

Significant deviations present. Needs to be hand coded.

```{sh eval=FALSE}
diff data_lvl01/317_Composting_Facility_NHCP_CPS_2020.yaml data_lvl01/317_Composting_Facility_PI_CPS_2017.yaml
```

## CSP 329 Residue and tillage management no till

TODO need to reprocess text

```{sh}
diff data_lvl01/329_Residue_And_Tillage_Management_No_Till_NHCP_CPS_0.yaml data_lvl01/329_Residue_and_Tillage_Management_No_Till_PI_CPS_2017.yaml
```

## CSP 380 Windbreak

```{sh}
diff data_lvl02/380_Windbreak_Shelterbelt_Establishment_NHCP_CPS_2021.yaml data_lvl02/380_Windbreak_Shelterbelt_Establishment_PIA_CPS_2022.yaml > data_lvl03/380_compare.log
```

```{r}
NHCP380 <- read_yaml('data_lvl02/380_Windbreak_Shelterbelt_Establishment_NHCP_CPS_2021.yaml')
PIA380 <- read_yaml('data_lvl02/380_Windbreak_Shelterbelt_Establishment_PIA_CPS_2022.yaml')

```


## CSP 379 Forest Farming

```{sh}
diff data_lvl02/379_Forest_Farming_NHCP_CPS_2020.yaml data_lvl02/379_Forest_Farming_PIA_CPS_2023.yaml > data_lvl03/379_compare.log
```

```{r}
PIA380 <- read_yaml('data_lvl02/380_Windbreak_Shelterbelt_Establishment_PIA_CPS_2022.yaml')

NHCP380 <- read_yaml('data_lvl02/380_Windbreak_Shelterbelt_Establishment_NHCP_CPS_2021.yaml')

#base::intersect(PIA380, NHCP380)
```
